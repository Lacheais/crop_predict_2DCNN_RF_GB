{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eru6gN7l9QbP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bbd9d19-469b-4e00-864a-82a4124457ac",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.11/dist-packages (1.4.7)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.16.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.4.26)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.14.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.4.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
            "Requirement already satisfied: optuna-integration[tfkeras] in /usr/local/lib/python3.11/dist-packages (4.4.0)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (from optuna-integration[tfkeras]) (4.4.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (from optuna-integration[tfkeras]) (2.18.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[tfkeras]) (1.16.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[tfkeras]) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[tfkeras]) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[tfkeras]) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[tfkeras]) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[tfkeras]) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[tfkeras]) (6.0.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->optuna-integration[tfkeras]) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->optuna-integration[tfkeras]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow->optuna-integration[tfkeras]) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->optuna-integration[tfkeras]) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->optuna-integration[tfkeras]) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->optuna-integration[tfkeras]) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow->optuna-integration[tfkeras]) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->optuna-integration[tfkeras]) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->optuna-integration[tfkeras]) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow->optuna-integration[tfkeras]) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->optuna-integration[tfkeras]) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->optuna-integration[tfkeras]) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow->optuna-integration[tfkeras]) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->optuna-integration[tfkeras]) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->optuna-integration[tfkeras]) (1.73.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow->optuna-integration[tfkeras]) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->optuna-integration[tfkeras]) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->optuna-integration[tfkeras]) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->optuna-integration[tfkeras]) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->optuna-integration[tfkeras]) (0.37.1)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna->optuna-integration[tfkeras]) (1.1.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow->optuna-integration[tfkeras]) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->optuna-integration[tfkeras]) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->optuna-integration[tfkeras]) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->optuna-integration[tfkeras]) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->optuna-integration[tfkeras]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->optuna-integration[tfkeras]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->optuna-integration[tfkeras]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->optuna-integration[tfkeras]) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->optuna-integration[tfkeras]) (3.2.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->optuna-integration[tfkeras]) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->optuna-integration[tfkeras]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->optuna-integration[tfkeras]) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow->optuna-integration[tfkeras]) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow->optuna-integration[tfkeras]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow->optuna-integration[tfkeras]) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow->optuna-integration[tfkeras]) (0.1.2)\n",
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.11/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.11/dist-packages (from flask-ngrok) (3.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from flask-ngrok) (2.32.3)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2025.4.26)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.11)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner\n",
        "!pip install openpyxl\n",
        "!pip install tensorflow\n",
        "!pip install optuna\n",
        "!pip install optuna-integration[tfkeras]\n",
        "!pip install flask pyngrok tensorflow scikit-learn joblib --quiet\n",
        "!pip install flask-ngrok\n",
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9BcZqE99V6s"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras_tuner as kt\n",
        "import io\n",
        "import shutil\n",
        "import joblib\n",
        "import random\n",
        "import optuna\n",
        "import random\n",
        "import threading\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.losses import mse\n",
        "from tensorflow.keras.metrics import mae\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from google.colab import files\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from optuna.integration import TFKerasPruningCallback\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Dropout, BatchNormalization, LeakyReLU, Reshape, Lambda, Multiply, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
        "from tensorflow.keras.models import load_model\n",
        "from flask import Flask, request, jsonify\n",
        "from pyngrok import ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "PLMNGWIn9ZST",
        "outputId": "d3f51bd3-d108-4c6f-ab31-46b3e2255ce1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7131d616-7a67-49c2-9664-32fceb279de7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7131d616-7a67-49c2-9664-32fceb279de7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving eksdidi (3).xlsx to eksdidi (3).xlsx\n"
          ]
        }
      ],
      "source": [
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0]\n",
        "df = pd.read_excel(io.BytesIO(uploaded[file_name]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWzLDh9u9a2M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bd6f1bf-17f4-4041-fda1-b60914ea76b1",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-17 02:16:56,005] A new study created in memory with name: no-name-9272386d-ceb6-43c3-8561-aec8fd0d1925\n",
            "[I 2025-06-17 02:21:30,028] Trial 0 finished with value: 1.1551836729049683 and parameters: {'conv1_filters': 64, 'conv1_kernel': 2, 'conv2_filters': 96, 'conv2_kernel': 2, 'conv3_filters': 32, 'conv3_kernel': 2, 'conv4_filters': 96, 'conv4_kernel': 3, 'conv5_filters': 128, 'conv5_kernel': 2, 'dense_units': 64, 'learning_rate': 0.0005}. Best is trial 0 with value: 1.1551836729049683.\n",
            "[I 2025-06-17 02:29:23,397] Trial 1 finished with value: 1.1301639080047607 and parameters: {'conv1_filters': 64, 'conv1_kernel': 2, 'conv2_filters': 64, 'conv2_kernel': 3, 'conv3_filters': 128, 'conv3_kernel': 3, 'conv4_filters': 96, 'conv4_kernel': 3, 'conv5_filters': 32, 'conv5_kernel': 3, 'dense_units': 128, 'learning_rate': 0.001}. Best is trial 1 with value: 1.1301639080047607.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Trial:\n",
            "{'conv1_filters': 64, 'conv1_kernel': 2, 'conv2_filters': 64, 'conv2_kernel': 3, 'conv3_filters': 128, 'conv3_kernel': 3, 'conv4_filters': 96, 'conv4_kernel': 3, 'conv5_filters': 32, 'conv5_kernel': 3, 'dense_units': 128, 'learning_rate': 0.001}\n",
            "Epoch 1/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - loss: 22.4299 - mae: 2.6250 - val_loss: 10.8782 - val_mae: 1.8671 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - loss: 11.3983 - mae: 1.7205 - val_loss: 8.0224 - val_mae: 1.2644 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 16ms/step - loss: 10.7056 - mae: 1.6419 - val_loss: 7.5107 - val_mae: 1.3203 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - loss: 9.9844 - mae: 1.5942 - val_loss: 7.0725 - val_mae: 1.3018 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 9.5746 - mae: 1.5454 - val_loss: 7.4495 - val_mae: 1.3557 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 16ms/step - loss: 9.5729 - mae: 1.5466 - val_loss: 6.8068 - val_mae: 1.1904 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 16ms/step - loss: 8.8997 - mae: 1.4766 - val_loss: 7.0320 - val_mae: 1.2580 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 14ms/step - loss: 8.3914 - mae: 1.4408 - val_loss: 7.2110 - val_mae: 1.3087 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 8.6585 - mae: 1.4630 - val_loss: 6.9846 - val_mae: 1.2998 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 8.5845 - mae: 1.4465 - val_loss: 6.6382 - val_mae: 1.2307 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - loss: 8.6087 - mae: 1.4475 - val_loss: 6.9747 - val_mae: 1.3937 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 7.9395 - mae: 1.4021 - val_loss: 6.4449 - val_mae: 1.1886 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - loss: 8.2261 - mae: 1.4067 - val_loss: 7.8576 - val_mae: 1.3590 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 8.1791 - mae: 1.4108 - val_loss: 6.4519 - val_mae: 1.2590 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 7.9404 - mae: 1.3881 - val_loss: 6.3776 - val_mae: 1.2467 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 8.1419 - mae: 1.3968 - val_loss: 6.8702 - val_mae: 1.2742 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - loss: 7.7866 - mae: 1.3663 - val_loss: 6.5330 - val_mae: 1.2492 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 7.4929 - mae: 1.3434 - val_loss: 6.6510 - val_mae: 1.1963 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - loss: 7.5854 - mae: 1.3470 - val_loss: 6.8133 - val_mae: 1.1437 - learning_rate: 0.0010\n",
            "Epoch 20/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - loss: 8.0383 - mae: 1.3828 - val_loss: 6.4670 - val_mae: 1.2356 - learning_rate: 0.0010\n",
            "Epoch 21/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 7.1909 - mae: 1.3006 - val_loss: 6.4497 - val_mae: 1.1886 - learning_rate: 5.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - loss: 7.2823 - mae: 1.3062 - val_loss: 6.5016 - val_mae: 1.2930 - learning_rate: 5.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 7.0176 - mae: 1.2926 - val_loss: 6.2853 - val_mae: 1.2046 - learning_rate: 5.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 6.9711 - mae: 1.2797 - val_loss: 6.2946 - val_mae: 1.2579 - learning_rate: 5.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 15ms/step - loss: 6.9025 - mae: 1.2793 - val_loss: 6.4807 - val_mae: 1.2356 - learning_rate: 5.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 7.1031 - mae: 1.2810 - val_loss: 6.4859 - val_mae: 1.2605 - learning_rate: 5.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 15ms/step - loss: 6.8235 - mae: 1.2696 - val_loss: 6.5532 - val_mae: 1.2627 - learning_rate: 5.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 6.7399 - mae: 1.2582 - val_loss: 6.4728 - val_mae: 1.2789 - learning_rate: 5.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 6.5122 - mae: 1.2489 - val_loss: 6.1730 - val_mae: 1.2036 - learning_rate: 2.5000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 6.4320 - mae: 1.2238 - val_loss: 6.1397 - val_mae: 1.1833 - learning_rate: 2.5000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 6.3292 - mae: 1.2202 - val_loss: 6.1164 - val_mae: 1.1708 - learning_rate: 2.5000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - loss: 6.4313 - mae: 1.2325 - val_loss: 6.2171 - val_mae: 1.2226 - learning_rate: 2.5000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 6.4635 - mae: 1.2399 - val_loss: 6.0815 - val_mae: 1.1494 - learning_rate: 2.5000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - loss: 6.2287 - mae: 1.2121 - val_loss: 6.1456 - val_mae: 1.1655 - learning_rate: 2.5000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 6.4095 - mae: 1.2393 - val_loss: 6.0922 - val_mae: 1.2056 - learning_rate: 2.5000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 15ms/step - loss: 6.0899 - mae: 1.2008 - val_loss: 6.0522 - val_mae: 1.2125 - learning_rate: 2.5000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 6.2676 - mae: 1.2229 - val_loss: 5.9594 - val_mae: 1.1609 - learning_rate: 2.5000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - loss: 6.0252 - mae: 1.1977 - val_loss: 6.1472 - val_mae: 1.1736 - learning_rate: 2.5000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 6.3170 - mae: 1.2228 - val_loss: 6.2952 - val_mae: 1.2475 - learning_rate: 2.5000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - loss: 6.0924 - mae: 1.2090 - val_loss: 5.9394 - val_mae: 1.1505 - learning_rate: 2.5000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 13ms/step - loss: 6.0984 - mae: 1.1981 - val_loss: 6.0538 - val_mae: 1.2163 - learning_rate: 2.5000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 6.2775 - mae: 1.2112 - val_loss: 6.0472 - val_mae: 1.1945 - learning_rate: 2.5000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 6.0798 - mae: 1.2085 - val_loss: 5.7685 - val_mae: 1.1512 - learning_rate: 2.5000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 5.9677 - mae: 1.1858 - val_loss: 5.9009 - val_mae: 1.1837 - learning_rate: 2.5000e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 6.1394 - mae: 1.2088 - val_loss: 5.7971 - val_mae: 1.1582 - learning_rate: 2.5000e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 6.1462 - mae: 1.2053 - val_loss: 6.0230 - val_mae: 1.1992 - learning_rate: 2.5000e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - loss: 6.2760 - mae: 1.2214 - val_loss: 6.1870 - val_mae: 1.2069 - learning_rate: 2.5000e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 5.9248 - mae: 1.1837 - val_loss: 6.1477 - val_mae: 1.1948 - learning_rate: 2.5000e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 6.0279 - mae: 1.1990 - val_loss: 5.8393 - val_mae: 1.1650 - learning_rate: 1.2500e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m840/840\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 5.9611 - mae: 1.1949 - val_loss: 5.8720 - val_mae: 1.1545 - learning_rate: 1.2500e-04\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
          ]
        }
      ],
      "source": [
        "# Reset tuner directory\n",
        "shutil.rmtree('tuner_results/crop_yield_bayesian', ignore_errors=True)\n",
        "\n",
        "# Fix random seeds\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Load Dataset\n",
        "label_encoder = LabelEncoder()\n",
        "df['Soil Type'] = label_encoder.fit_transform(df['Soil Type'])\n",
        "\n",
        "selected_columns = ['Soil Type', 'Moisture_1', 'Moisture_2', 'Moisture_3',\n",
        "                    'Luminosity_1', 'Luminosity_2', 'Luminosity_3',\n",
        "                    'Duration_1', 'Duration_2', 'Duration_3', 'Total Duration', 'Yield/Plant']\n",
        "df = df[selected_columns]\n",
        "\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "# Upsampling\n",
        "def upsample_high_yield(X, y, threshold=8.0, factor=3):\n",
        "    high_idx = np.where(y >= threshold)[0]\n",
        "    X_high = X[high_idx]\n",
        "    y_high = y[high_idx]\n",
        "    X_upsampled = np.concatenate([X] + [X_high] * (factor - 1), axis=0)\n",
        "    y_upsampled = np.concatenate([y] + [y_high] * (factor - 1), axis=0)\n",
        "    indices = np.arange(len(X_upsampled))\n",
        "    np.random.shuffle(indices)\n",
        "    return X_upsampled[indices], y_upsampled[indices]\n",
        "\n",
        "X_upsampled, y_upsampled = upsample_high_yield(X, y, threshold=8.0, factor=3)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_upsampled, y_upsampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Padding\n",
        "num_features_needed = 12\n",
        "\n",
        "def pad_dataset(data, num_features_needed, pad_value=0.0):\n",
        "    if data.shape[1] < num_features_needed:\n",
        "        padding = np.full((data.shape[0], num_features_needed - data.shape[1]), pad_value)\n",
        "        data = np.concatenate([data, padding], axis=1)\n",
        "    return data\n",
        "\n",
        "X_train = pad_dataset(X_train, num_features_needed)\n",
        "X_test = pad_dataset(X_test, num_features_needed)\n",
        "\n",
        "# Scaling\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Reshape for CNN\n",
        "X_train = X_train.reshape(X_train.shape[0], 3, 4, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 3, 4, 1)\n",
        "\n",
        "# Weighted MSE\n",
        "def weighted_mse(y_true, y_pred):\n",
        "    weight = 1.0 + tf.square((y_true - 8.0) / 2.0)\n",
        "    error = tf.square(y_true - y_pred)\n",
        "    return tf.reduce_mean(weight * error)\n",
        "\n",
        "def softmax_axis1(z):\n",
        "    return K.softmax(z, axis=1)\n",
        "\n",
        "def softmax_output_shape(shape):\n",
        "    return shape\n",
        "\n",
        "def sum_axis1(z):\n",
        "    return K.sum(z, axis=1)\n",
        "\n",
        "def sum_output_shape(shape):\n",
        "    return (shape[0], shape[2])\n",
        "\n",
        "# CNN Model\n",
        "def create_model(trial):\n",
        "    inputs = Input(shape=(3, 4, 1))\n",
        "    x = inputs\n",
        "    for i in range(5):\n",
        "        x = Conv2D(filters=trial.suggest_int(f'conv{i+1}_filters', 32, 128, step=32),\n",
        "                   kernel_size=trial.suggest_categorical(f'conv{i+1}_kernel', [2, 3]),\n",
        "                   padding='same', kernel_regularizer=l2(1e-4))(x)\n",
        "        x = LeakyReLU(0.1)(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "\n",
        "    flatten_shape = x.shape[1] * x.shape[2]\n",
        "    channels = x.shape[-1]\n",
        "    reshaped = Reshape((flatten_shape, channels))(x)\n",
        "\n",
        "    attention_scores = Dense(1, activation='tanh')(reshaped)\n",
        "    attention_weights = Lambda(softmax_axis1, output_shape=softmax_output_shape)(attention_scores)\n",
        "    context_vector = Multiply()([reshaped, attention_weights])\n",
        "    context_vector = Lambda(sum_axis1, output_shape=sum_output_shape)(context_vector)\n",
        "\n",
        "    x = Dense(trial.suggest_int('dense_units', 64, 128, step=32), kernel_regularizer=l2(1e-4))(context_vector)\n",
        "    x = LeakyReLU(0.1)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    output = Dense(1, activation='linear')(x)\n",
        "    model = Model(inputs, output)\n",
        "\n",
        "    lr = trial.suggest_categorical('learning_rate', [1e-3, 5e-4, 1e-4])\n",
        "    model.compile(optimizer=Adam(learning_rate=lr), loss=weighted_mse, metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "# Optuna Objective\n",
        "def objective(trial):\n",
        "    model = create_model(trial)\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_test, y_test),\n",
        "        epochs=30,\n",
        "        batch_size=16,\n",
        "        verbose=0,\n",
        "        callbacks=[early_stopping, reduce_lr, TFKerasPruningCallback(trial, 'val_loss')]\n",
        "    )\n",
        "    return min(history.history['val_mae'])\n",
        "\n",
        "# Run Optuna\n",
        "study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(seed=42))\n",
        "study.optimize(objective, n_trials=2, timeout=1200)\n",
        "print(\"Best Trial:\")\n",
        "print(study.best_trial.params)\n",
        "\n",
        "# Train Final CNN\n",
        "best_model = create_model(study.best_trial)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)\n",
        "\n",
        "history = best_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")\n",
        "\n",
        "# Save Model\n",
        "best_model.save(\"best_crop_yield_model_optuna.keras\")\n",
        "\n",
        "# Random Forest + Ensemble\n",
        "cnn_preds = best_model.predict(X_test).flatten()\n",
        "X_train_rf = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test_rf = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train_rf, y_train)\n",
        "rf_preds = rf_model.predict(X_test_rf)\n",
        "\n",
        "stacked_input = np.vstack((cnn_preds, rf_preds)).T\n",
        "\n",
        "# Stacked Ensemble - Gradient Boosting\n",
        "meta_model_gb = GradientBoostingRegressor(n_estimators=600, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "meta_model_gb.fit(stacked_input, y_test)\n",
        "gb_preds = meta_model_gb.predict(stacked_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_NES1bt9y3L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9e14d1c-f536-4dae-82c2-c61b06d041c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rf_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Save Gradient Boosting Meta Model\n",
        "joblib.dump(meta_model_gb, \"final_meta_model_gb.pkl\")\n",
        "\n",
        "# Save Scaler\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "\n",
        "# Save Label Encoder (if you’ll use it later for new data)\n",
        "joblib.dump(label_encoder, \"soil_label_encoder.pkl\")\n",
        "\n",
        "#Save Random Fores\n",
        "joblib.dump(rf_model, \"rf_model.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbKez6Hn9_PT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d71cfad9-a755-4ce4-8c84-b00f7aa3b89f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Yield/Plant: 5.59\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import joblib\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import backend as K\n",
        "from keras.config import enable_unsafe_deserialization\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "enable_unsafe_deserialization()\n",
        "\n",
        "# === Custom Loss ===\n",
        "def weighted_mse(y_true, y_pred):\n",
        "    weight = 1.0 + tf.square((y_true - 8.0) / 2.0)\n",
        "    error = tf.square(y_true - y_pred)\n",
        "    return tf.reduce_mean(weight * error)\n",
        "\n",
        "# === Load Models & Tools ===\n",
        "best_model = load_model(\n",
        "    \"best_crop_yield_model_optuna.keras\",\n",
        "    custom_objects={\n",
        "        'weighted_mse': weighted_mse,\n",
        "        'softmax_axis1': softmax_axis1,\n",
        "        'softmax_output_shape': softmax_output_shape,\n",
        "        'sum_axis1': sum_axis1,\n",
        "        'sum_output_shape': sum_output_shape\n",
        "    }\n",
        ")\n",
        "rf_model = joblib.load(\"rf_model.pkl\")\n",
        "meta_model_gb = joblib.load(\"final_meta_model_gb.pkl\")\n",
        "scaler = joblib.load(\"scaler.pkl\")\n",
        "label_encoder = joblib.load(\"soil_label_encoder.pkl\")\n",
        "\n",
        "# === Predict Function ===\n",
        "def predict_crop_yield(input_dict):\n",
        "    soil_type_encoded = input_dict['Soil Type']\n",
        "\n",
        "    features = [\n",
        "        soil_type_encoded,\n",
        "        input_dict['Moisture_1'],\n",
        "        input_dict['Moisture_2'],\n",
        "        input_dict['Moisture_3'],\n",
        "        input_dict['Luminosity_1'],\n",
        "        input_dict['Luminosity_2'],\n",
        "        input_dict['Luminosity_3'],\n",
        "        input_dict['Duration_1'],\n",
        "        input_dict['Duration_2'],\n",
        "        input_dict['Duration_3'],\n",
        "        input_dict['Total Duration']\n",
        "    ]\n",
        "    features = np.array(features, dtype=np.float32).reshape(1, -1)\n",
        "\n",
        "    # Pad to 12 features if needed\n",
        "    if features.shape[1] < 12:\n",
        "        features = np.concatenate([features, np.zeros((1, 12 - features.shape[1]), dtype=np.float32)], axis=1)\n",
        "\n",
        "    # Scale features\n",
        "    features_scaled = scaler.transform(features)\n",
        "\n",
        "    # CNN prediction: ensure shape (1, 3, 4, 1) and dtype float32\n",
        "    features_cnn = tf.convert_to_tensor(features_scaled.reshape(1, 3, 4, 1), dtype=tf.float32)\n",
        "    cnn_pred = best_model.predict(features_cnn, verbose=0).flatten()\n",
        "\n",
        "    # RF prediction\n",
        "    rf_pred = rf_model.predict(features_scaled.reshape(1, -1))\n",
        "\n",
        "    # Stacked ensemble prediction\n",
        "    stacked_input = np.vstack((cnn_pred, rf_pred)).T\n",
        "    final_pred = meta_model_gb.predict(stacked_input)\n",
        "\n",
        "    return final_pred[0]\n",
        "\n",
        "# === Example Usage ===\n",
        "new_sample = {\n",
        "    'Soil Type': 0,\n",
        "    'Luminosity_1': 5847.85,\n",
        "    'Luminosity_2': 4339.5,\n",
        "    'Luminosity_3': 1489.4,\n",
        "    'Moisture_1': 90.61,\n",
        "    'Moisture_2': 41.56,\n",
        "    'Moisture_3': 81.77,\n",
        "    'Duration_1': 36,\n",
        "    'Duration_2': 34,\n",
        "    'Duration_3': 38,\n",
        "    'Total Duration': 108\n",
        "}\n",
        "\n",
        "predicted_yield = predict_crop_yield(new_sample)\n",
        "print(f\"Predicted Yield/Plant: {predicted_yield:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jyga2xyW-L6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02c819d2-bf5c-402b-a61f-eb25a74da8d5",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LabelEncoder classes: ['Loamy' 'Sandy']\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        }
      ],
      "source": [
        "soil_types = ['Loamy', 'Sandy']\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(soil_types)\n",
        "\n",
        "joblib.dump(label_encoder, \"soil_label_encoder.pkl\")\n",
        "\n",
        "print(\"LabelEncoder classes:\", label_encoder.classes_)\n",
        "\n",
        "\n",
        "best_model = tf.keras.models.load_model(\n",
        "    \"best_crop_yield_model_optuna.keras\",\n",
        "    custom_objects={\n",
        "        'weighted_mse': weighted_mse,\n",
        "        'softmax_axis1': softmax_axis1,\n",
        "        'softmax_output_shape': softmax_output_shape,\n",
        "        'sum_axis1': sum_axis1,\n",
        "        'sum_output_shape': sum_output_shape\n",
        "    }\n",
        ")\n",
        "rf_model = joblib.load(\"rf_model.pkl\")\n",
        "meta_model_gb = joblib.load(\"final_meta_model_gb.pkl\")\n",
        "scaler = joblib.load(\"scaler.pkl\")\n",
        "label_encoder = joblib.load(\"soil_label_encoder.pkl\")\n",
        "\n",
        "def weighted_mse(y_true, y_pred):\n",
        "    weight = 1.0 + tf.square((y_true - 8.0) / 2.0)\n",
        "    error = tf.square(y_true - y_pred)\n",
        "    return tf.reduce_mean(weight * error)\n",
        "\n",
        "def predict_crop_yield(input_dict):\n",
        "    # Ensure SoilType is a plain Python string\n",
        "    soil_type_encoded = label_encoder.transform([str(input_dict['SoilType'])])[0]\n",
        "\n",
        "    features = [\n",
        "        soil_type_encoded,\n",
        "        input_dict['Moisture_1'],\n",
        "        input_dict['Moisture_2'],\n",
        "        input_dict['Moisture_3'],\n",
        "        input_dict['Luminosity_1'],\n",
        "        input_dict['Luminosity_2'],\n",
        "        input_dict['Luminosity_3'],\n",
        "        input_dict['Duration_1'],\n",
        "        input_dict['Duration_2'],\n",
        "        input_dict['Duration_3'],\n",
        "        input_dict['Total Duration']\n",
        "    ]\n",
        "    features = np.array(features).reshape(1, -1)\n",
        "\n",
        "    if features.shape[1] < 12:\n",
        "        features = np.concatenate([features, np.zeros((1, 12 - features.shape[1]))], axis=1)\n",
        "\n",
        "    # Scale features\n",
        "    features_scaled = scaler.transform(features)\n",
        "\n",
        "    # CNN prediction\n",
        "    features_cnn = features_scaled.reshape(1, 3, 4, 1)\n",
        "    cnn_pred = best_model.predict(features_cnn).flatten()\n",
        "\n",
        "    # RF prediction\n",
        "    features_rf = features_scaled.reshape(1, -1)\n",
        "    rf_pred = rf_model.predict(features_rf)\n",
        "\n",
        "    # Stacked ensemble prediction\n",
        "    stacked_input = np.vstack((cnn_pred, rf_pred)).T\n",
        "    final_pred = meta_model_gb.predict(stacked_input)\n",
        "\n",
        "    return final_pred[0]\n",
        "\n",
        "# === Flask API setup ===\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    try:\n",
        "        data = request.get_json()  # Get JSON data from the request\n",
        "        if not data:\n",
        "            return jsonify({'error': 'No data received'}), 400\n",
        "        print(f\"Received data: {data}\")  # Log received data for debugging\n",
        "        prediction = predict_crop_yield(data)\n",
        "        return jsonify({'predicted_yield': prediction}), 200\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")  # Log the exception for debugging\n",
        "        return jsonify({'error': str(e)}), 400  # Handle any errors\n",
        "\n",
        "# Function to start the Flask server\n",
        "def start_flask():\n",
        "    app.run(host='0.0.0.0', port=5000)\n",
        "\n",
        "# Function to start Ngrok tunnel\n",
        "def start_ngrok():\n",
        "    public_url = ngrok.connect(5000)\n",
        "    print(f'Ngrok tunnel \"{public_url}\" is running')\n",
        "\n",
        "# Create separate threads for Flask and Ngrok\n",
        "flask_thread = threading.Thread(target=start_flask)\n",
        "ngrok_thread = threading.Thread(target=start_ngrok)\n",
        "\n",
        "# Start both threads\n",
        "flask_thread.start()\n",
        "ngrok_thread.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Y1lC3LW-0HW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c0367ca-ee59-4205-f506-8991ff502061"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken 123456789 #replace this with your own ngrok authorization token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZThIHzW-6Fs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "500c4a8d-5d1e-4463-c83f-d872ec4e4335",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 03:01:27] \"\u001b[33mGET /robots.txt HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 03:01:28] \"\u001b[31m\u001b[1mGET /predict HTTP/1.1\u001b[0m\" 405 -\n",
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 03:01:32] \"\u001b[33mGET /robots.txt HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 03:01:32] \"\u001b[33mGET /robots.txt HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 03:01:32] \"\u001b[31m\u001b[1mGET /predict HTTP/1.1\u001b[0m\" 405 -\n",
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 03:01:33] \"\u001b[31m\u001b[1mGET /predict HTTP/1.1\u001b[0m\" 405 -\n",
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 03:01:33] \"\u001b[33mGET /robots.txt HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Received data: {'SoilType': 'Loamy', 'Luminosity_1': 4535.0, 'Luminosity_2': 4024.0, 'Luminosity_3': 4754.0, 'Moisture_1': 65.38981, 'Moisture_2': 66.61212, 'Moisture_3': 72.7235947, 'Duration_1': 27.13377, 'Duration_2': 29.08944, 'Duration_3': 29.08944, 'Total Duration': 85.31265}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 03:02:40] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Received data: {'SoilType': 'Sandy', 'Luminosity_1': 2345.0, 'Luminosity_2': 4299.0, 'Luminosity_3': 3235.0, 'Moisture_1': 62.9452171, 'Moisture_2': 83.5695953, 'Moisture_3': 83.68281, 'Duration_1': 29.08944, 'Duration_2': 26.5685959, 'Duration_3': 23.0017929, 'Total Duration': 78.65983}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 03:04:06] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Received data: {'SoilType': 'Sandy', 'Luminosity_1': 2345.0, 'Luminosity_2': 4299.0, 'Luminosity_3': 3235.0, 'Moisture_1': 62.9452171, 'Moisture_2': 83.5695953, 'Moisture_3': 83.68281, 'Duration_1': 29.08944, 'Duration_2': 26.5685959, 'Duration_3': 23.0017929, 'Total Duration': 78.65983}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 03:04:06] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Received data: {'SoilType': 'Loamy', 'Luminosity_1': 0.0, 'Luminosity_2': 0.0, 'Luminosity_3': 0.0, 'Moisture_1': 0.0, 'Moisture_2': 0.0, 'Moisture_3': 0.0, 'Duration_1': 0.0, 'Duration_2': 0.0, 'Duration_3': 0.0, 'Total Duration': 0.0}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 03:04:13] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Received data: {'SoilType': 'Loamy', 'Luminosity_1': 6000.0, 'Luminosity_2': 3686.0, 'Luminosity_3': 5529.0, 'Moisture_1': 73.96671, 'Moisture_2': 70.6502762, 'Moisture_3': 37.725872, 'Duration_1': 22.1264744, 'Duration_2': 32.10129, 'Duration_3': 14.8159866, 'Total Duration': 69.0437546}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 03:05:04] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Received data: {'SoilType': 'Sandy', 'Luminosity_1': 5159.0, 'Luminosity_2': 4913.0, 'Luminosity_3': 4831.0, 'Moisture_1': 84.94149, 'Moisture_2': 78.0822449, 'Moisture_3': 85.62743, 'Duration_1': 31.7816238, 'Duration_2': 23.2761688, 'Duration_3': 34.5253258, 'Total Duration': 89.5831146}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 03:06:24] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Received data: {'SoilType': 'Loamy', 'Luminosity_1': 2005.0, 'Luminosity_2': 1310.0, 'Luminosity_3': 1965.0, 'Moisture_1': 25.9519043, 'Moisture_2': 50.75845, 'Moisture_3': 58.87633, 'Duration_1': 26.8882637, 'Duration_2': 26.5685959, 'Duration_3': 34.2509727, 'Total Duration': 87.70783}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 03:07:07] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Received data: {'SoilType': 'Sandy', 'Luminosity_1': 3809.0, 'Luminosity_2': 2785.0, 'Luminosity_3': 3113.0, 'Moisture_1': 42.5273628, 'Moisture_2': 61.62001, 'Moisture_3': 38.9844742, 'Duration_1': 33.47314, 'Duration_2': 28.8088512, 'Duration_3': 35.34843, 'Total Duration': 97.6304245}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 03:07:40] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Received data: {'SoilType': 'Sandy', 'Luminosity_1': 3809.0, 'Luminosity_2': 2785.0, 'Luminosity_3': 3113.0, 'Moisture_1': 42.5273628, 'Moisture_2': 61.62001, 'Moisture_3': 38.9844742, 'Duration_1': 33.47314, 'Duration_2': 28.8088512, 'Duration_3': 35.34843, 'Total Duration': 97.6304245}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 03:07:41] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Received data: {'SoilType': 'Loamy', 'Luminosity_1': 5488.0, 'Luminosity_2': 4710.0, 'Luminosity_3': 3645.0, 'Moisture_1': 70.6502762, 'Moisture_2': 50.75845, 'Moisture_3': 87.79841, 'Duration_1': 22.223959, 'Duration_2': 33.4731445, 'Duration_3': 20.2580929, 'Total Duration': 75.9552}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 03:15:29] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Received data: {'SoilType': 'Sandy', 'Luminosity_1': 3357.0, 'Luminosity_2': 5816.0, 'Luminosity_3': 5447.0, 'Moisture_1': 100.0, 'Moisture_2': 86.42653, 'Moisture_3': 71.33622, 'Duration_1': 24.9676685, 'Duration_2': 29.35759, 'Duration_3': 29.9063339, 'Total Duration': 84.23159}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 03:21:01] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Received data: {'SoilType': 'Sandy', 'Luminosity_1': 3726.0, 'Luminosity_2': 4504.0, 'Luminosity_3': 4708.0, 'Moisture_1': 77.3963, 'Moisture_2': 78.0822449, 'Moisture_3': 76.02447, 'Duration_1': 29.03793, 'Duration_2': 30.1354122, 'Duration_3': 30.6841431, 'Total Duration': 89.85748}\n",
            "Received data: {'SoilType': 'Sandy', 'Luminosity_1': 3726.0, 'Luminosity_2': 4504.0, 'Luminosity_3': 4708.0, 'Moisture_1': 77.3963, 'Moisture_2': 78.0822449, 'Moisture_3': 76.02447, 'Duration_1': 29.03793, 'Duration_2': 30.1354122, 'Duration_3': 30.6841431, 'Total Duration': 89.85748}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 03:24:09] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 03:24:09] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Received data: {'SoilType': 'Sandy', 'Luminosity_1': 1760.0, 'Luminosity_2': 3316.0, 'Luminosity_3': 5119.0, 'Moisture_1': 28.009697, 'Moisture_2': 26.6378441, 'Moisture_3': 73.28076, 'Duration_1': 28.4891987, 'Duration_2': 39.1896248, 'Duration_3': 32.056, 'Total Duration': 99.7348251}\n",
            "Received data: {'SoilType': 'Sandy', 'Luminosity_1': 1760.0, 'Luminosity_2': 3316.0, 'Luminosity_3': 5119.0, 'Moisture_1': 28.009697, 'Moisture_2': 26.6378441, 'Moisture_3': 73.28076, 'Duration_1': 28.4891987, 'Duration_2': 39.1896248, 'Duration_3': 32.056, 'Total Duration': 99.7348251}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 03:24:43] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 03:24:43] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Received data: {'SoilType': 'Sandy', 'Luminosity_1': 1760.0, 'Luminosity_2': 3316.0, 'Luminosity_3': 5119.0, 'Moisture_1': 28.009697, 'Moisture_2': 26.6378441, 'Moisture_3': 73.28076, 'Duration_1': 28.4891987, 'Duration_2': 39.1896248, 'Duration_3': 32.056, 'Total Duration': 99.7348251}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 03:24:43] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Received data: {'SoilType': 'Sandy', 'Luminosity_1': 4874.0, 'Luminosity_2': 3686.0, 'Luminosity_3': 3357.0, 'Moisture_1': 53.3889427, 'Moisture_2': 25.3792114, 'Moisture_3': 43.8991776, 'Duration_1': 14.4963322, 'Duration_2': 23.8249111, 'Duration_3': 28.4891987, 'Total Duration': 66.81044}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/stepReceived data: {'SoilType': 'Sandy', 'Luminosity_1': 4874.0, 'Luminosity_2': 3686.0, 'Luminosity_3': 3357.0, 'Moisture_1': 53.3889427, 'Moisture_2': 25.3792114, 'Moisture_3': 43.8991776, 'Duration_1': 14.4963322, 'Duration_2': 23.8249111, 'Duration_3': 28.4891987, 'Total Duration': 66.81044}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 03:25:07] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 03:25:07] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Received data: {'SoilType': 'Sandy', 'Luminosity_1': 5036.0, 'Luminosity_2': 4913.0, 'Luminosity_3': 4463.0, 'Moisture_1': 76.71036, 'Moisture_2': 80.14, 'Moisture_3': 74.65259, 'Duration_1': 30.958519, 'Duration_2': 32.6047363, 'Duration_3': 28.21482, 'Total Duration': 91.7780762}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 03:25:32] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Received data: {'SoilType': 'Sandy', 'Luminosity_1': 4545.0, 'Luminosity_2': 4381.0, 'Luminosity_3': 4545.0, 'Moisture_1': 78.76819, 'Moisture_2': 66.42149, 'Moisture_3': 65.04967, 'Duration_1': 33.4278374, 'Duration_2': 28.4891987, 'Duration_3': 30.6841431, 'Total Duration': 92.60118}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 03:25:57] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Received data: {'SoilType': 'Sandy', 'Luminosity_1': 3113.0, 'Luminosity_2': 4504.0, 'Luminosity_3': 4463.0, 'Moisture_1': 82.31096, 'Moisture_2': 82.19778, 'Moisture_3': 78.76819, 'Duration_1': 28.4891987, 'Duration_2': 29.3123055, 'Duration_3': 27.1173363, 'Total Duration': 84.91884}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 03:34:22] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Received data: {'SoilType': 'Loamy', 'Luminosity_1': 4791.0, 'Luminosity_2': 3276.0, 'Luminosity_3': 3809.0, 'Moisture_1': 56.93179, 'Moisture_2': 75.45178, 'Moisture_3': 82.99694, 'Duration_1': 31.55254, 'Duration_2': 34.02188, 'Duration_3': 26.3395157, 'Total Duration': 91.91394}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [17/Jun/2025 03:37:58] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "!ngrok http 5000"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}